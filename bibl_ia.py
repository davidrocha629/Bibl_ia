# -*- coding: utf-8 -*-
"""Bibl_ia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/davidrocha629/Bibl_ia/blob/main/Bibl_ia.ipynb

**Configurações iniciais padrão**

Aqui foi mantida a configuração inicial baseado na consulta gerada no Goggle IA Studio, sendo possivel replicar atraves do link https://aistudio.google.com/

Modificando apenas o detalhe da api key para proteger o codigo API, conforme detalhado na aula 4 da imersão Alura+Google IA.
"""

"""
At the command line, only need to run once to install the package via pip:

$ pip install google-generativeai
"""


import google.generativeai as genai
from google.colab import userdata
api_key = userdata.get('SECRET_KEY')
genai.configure(api_key=api_key)


# Set up the model
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 0,
  "max_output_tokens": 8192,
}

safety_settings = [
  {
    "category": "HARM_CATEGORY_HARASSMENT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_HATE_SPEECH",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
  {
    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
  },
]

"""**Configurações secundarias, mais especificas.**

 Aqui é onde definimos o modelo do Gemini a ser usado, nesse caso o 1.5 pro latest, para modelar o comportamento do chat. Também dando o direcionamento do comportamento das respostas do chat "system_instruction";
"""

system_instruction = "Haja como um doutor em teologia cristã e pastor leitor da biblia e conhecedor de todos os trechos da bliblia cristã, que lê as mensagens do chat e responde com uma mensagem positiva baseado na biblia, citando sempre a fonte, livro, capitulo e versiculos citados. Responda de forma simples e entendivel, e demonstre compaixão, amor ao proximo e vontade de ajudar. Ao final de cada resposta incentive de forma cautelosa a pessoa a falar mais um pouco"

model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest",
                              generation_config=generation_config,
                              system_instruction=system_instruction,
                              safety_settings=safety_settings)

chat = model.start_chat(history=[])

"""**Chat em si.**

Aqui é onde é testado o codigo, enviando mensagens e aguardando a resposta, como estamos acostumados a fazer com chat de IAs.
"""

prompt = input("Olá, como você está: ")
while prompt != "fim":
  response = chat.send_message(prompt)
  print( "\n", response.text, "\n")
  prompt = input()

"""**FIM**

É possivel testar esse codigo atraves do link a seguir usando o Google IA Studio https://aistudio.google.com/app/prompts/1ufgS4T-vseqe-58WsYOMiz7Kh-K1K4Lk ou abrindo esse projeto no Google Colab.

Teste o chat e tenha um ótimo dia.
"""